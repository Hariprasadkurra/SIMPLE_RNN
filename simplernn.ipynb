{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a96f3b11-ac58-45af-bb11-c1987f3f25eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Load the text file\n",
    "with open(r\"C:\\Users\\Happy\\OneDrive\\Pictures\\Screenshots\\rnntext.txt\", 'r') as file:\n",
    "    text = file.read()\n",
    "\n",
    "# Clean and preprocess\n",
    "text = text.lower()\n",
    "text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "words = text.split()\n",
    "\n",
    "# Tokenize and create sequences\n",
    "sequence_length = 4\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([text])\n",
    "\n",
    "sequences = []\n",
    "for i in range(sequence_length, len(words)):\n",
    "    seq = words[i-sequence_length:i+1]\n",
    "    sequences.append(seq)\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(sequences)\n",
    "sequences = np.array(sequences)\n",
    "\n",
    "X, y = sequences[:, :-1], sequences[:, -1]\n",
    "y = to_categorical(y, num_classes=len(tokenizer.word_index) + 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08d7674-59e4-416d-a3a8-e3cf0bc03005",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d84308dd-4910-4b2b-adb5-cc61df95e161",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([89,  1, 46, 90, 91])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a9cdf8c-62b8-4f41-a23d-341edc7faeef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 89,   1,  46,  90],\n",
       "       [  1,  46,  90,  91],\n",
       "       [ 46,  90,  91,  92],\n",
       "       ...,\n",
       "       [ 60,   3,  42,  18],\n",
       "       [  3,  42,  18, 363],\n",
       "       [ 42,  18, 363,   1]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "26c6f566-8d6a-4a0e-a29b-cca159963c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense,GRU\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b032c8de-07a2-416f-9a75-a365a58d27ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "embedding_dim = 50\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a311620b-bd77-4d95-aa71-6cd5af34134f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_dim, input_length=sequence_length-1))\n",
    "model.add(GRU(50))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5819d74a-24e3-45a6-979d-8b7c036c00c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "24/24 - 5s - 222ms/step - accuracy: 0.0535 - loss: 5.8908\n",
      "Epoch 2/100\n",
      "24/24 - 0s - 7ms/step - accuracy: 0.0816 - loss: 5.8179\n",
      "Epoch 3/100\n",
      "24/24 - 0s - 7ms/step - accuracy: 0.0816 - loss: 5.4459\n",
      "Epoch 4/100\n",
      "24/24 - 0s - 7ms/step - accuracy: 0.0816 - loss: 5.2129\n",
      "Epoch 5/100\n",
      "24/24 - 0s - 7ms/step - accuracy: 0.0816 - loss: 5.1415\n",
      "Epoch 6/100\n",
      "24/24 - 0s - 7ms/step - accuracy: 0.0816 - loss: 5.0764\n",
      "Epoch 7/100\n",
      "24/24 - 0s - 7ms/step - accuracy: 0.0816 - loss: 5.0310\n",
      "Epoch 8/100\n",
      "24/24 - 0s - 7ms/step - accuracy: 0.0816 - loss: 4.9690\n",
      "Epoch 9/100\n",
      "24/24 - 0s - 7ms/step - accuracy: 0.0829 - loss: 4.9231\n",
      "Epoch 10/100\n",
      "24/24 - 0s - 7ms/step - accuracy: 0.0842 - loss: 4.8530\n",
      "Epoch 11/100\n",
      "24/24 - 0s - 7ms/step - accuracy: 0.0829 - loss: 4.7753\n",
      "Epoch 12/100\n",
      "24/24 - 0s - 7ms/step - accuracy: 0.0869 - loss: 4.6748\n",
      "Epoch 13/100\n",
      "24/24 - 0s - 7ms/step - accuracy: 0.0922 - loss: 4.5432\n",
      "Epoch 14/100\n",
      "24/24 - 0s - 7ms/step - accuracy: 0.1043 - loss: 4.4133\n",
      "Epoch 15/100\n",
      "24/24 - 0s - 7ms/step - accuracy: 0.1123 - loss: 4.2961\n",
      "Epoch 16/100\n",
      "24/24 - 0s - 7ms/step - accuracy: 0.1217 - loss: 4.1696\n",
      "Epoch 17/100\n",
      "24/24 - 0s - 7ms/step - accuracy: 0.1283 - loss: 4.0495\n",
      "Epoch 18/100\n",
      "24/24 - 0s - 7ms/step - accuracy: 0.1310 - loss: 3.9391\n",
      "Epoch 19/100\n",
      "24/24 - 0s - 10ms/step - accuracy: 0.1551 - loss: 3.8280\n",
      "Epoch 20/100\n",
      "24/24 - 0s - 8ms/step - accuracy: 0.1564 - loss: 3.7133\n",
      "Epoch 21/100\n",
      "24/24 - 0s - 7ms/step - accuracy: 0.1898 - loss: 3.5905\n",
      "Epoch 22/100\n",
      "24/24 - 0s - 7ms/step - accuracy: 0.1979 - loss: 3.4672\n",
      "Epoch 23/100\n",
      "24/24 - 0s - 8ms/step - accuracy: 0.2286 - loss: 3.3410\n",
      "Epoch 24/100\n",
      "24/24 - 0s - 7ms/step - accuracy: 0.2326 - loss: 3.2084\n",
      "Epoch 25/100\n",
      "24/24 - 0s - 8ms/step - accuracy: 0.2580 - loss: 3.0778\n",
      "Epoch 26/100\n",
      "24/24 - 0s - 7ms/step - accuracy: 0.2754 - loss: 2.9527\n",
      "Epoch 27/100\n",
      "24/24 - 0s - 9ms/step - accuracy: 0.2968 - loss: 2.8007\n",
      "Epoch 28/100\n",
      "24/24 - 0s - 8ms/step - accuracy: 0.3115 - loss: 2.6734\n",
      "Epoch 29/100\n",
      "24/24 - 0s - 8ms/step - accuracy: 0.3329 - loss: 2.5458\n",
      "Epoch 30/100\n",
      "24/24 - 0s - 9ms/step - accuracy: 0.3650 - loss: 2.4072\n",
      "Epoch 31/100\n",
      "24/24 - 0s - 7ms/step - accuracy: 0.3810 - loss: 2.2908\n",
      "Epoch 32/100\n",
      "24/24 - 0s - 10ms/step - accuracy: 0.4265 - loss: 2.1647\n",
      "Epoch 33/100\n",
      "24/24 - 0s - 13ms/step - accuracy: 0.4492 - loss: 2.0737\n",
      "Epoch 34/100\n",
      "24/24 - 0s - 12ms/step - accuracy: 0.4866 - loss: 1.9703\n",
      "Epoch 35/100\n",
      "24/24 - 0s - 13ms/step - accuracy: 0.5027 - loss: 1.8482\n",
      "Epoch 36/100\n",
      "24/24 - 0s - 12ms/step - accuracy: 0.5481 - loss: 1.7304\n",
      "Epoch 37/100\n",
      "24/24 - 0s - 7ms/step - accuracy: 0.5936 - loss: 1.6316\n",
      "Epoch 38/100\n",
      "24/24 - 0s - 7ms/step - accuracy: 0.6257 - loss: 1.5412\n",
      "Epoch 39/100\n",
      "24/24 - 0s - 10ms/step - accuracy: 0.6832 - loss: 1.4385\n",
      "Epoch 40/100\n",
      "24/24 - 0s - 13ms/step - accuracy: 0.6858 - loss: 1.3734\n",
      "Epoch 41/100\n",
      "24/24 - 0s - 13ms/step - accuracy: 0.7166 - loss: 1.2810\n",
      "Epoch 42/100\n",
      "24/24 - 0s - 11ms/step - accuracy: 0.7473 - loss: 1.1954\n",
      "Epoch 43/100\n",
      "24/24 - 0s - 9ms/step - accuracy: 0.7834 - loss: 1.1337\n",
      "Epoch 44/100\n",
      "24/24 - 0s - 10ms/step - accuracy: 0.7955 - loss: 1.0527\n",
      "Epoch 45/100\n",
      "24/24 - 0s - 8ms/step - accuracy: 0.8222 - loss: 0.9831\n",
      "Epoch 46/100\n",
      "24/24 - 0s - 8ms/step - accuracy: 0.8262 - loss: 0.9308\n",
      "Epoch 47/100\n",
      "24/24 - 0s - 14ms/step - accuracy: 0.8356 - loss: 0.8696\n",
      "Epoch 48/100\n",
      "24/24 - 0s - 10ms/step - accuracy: 0.8703 - loss: 0.8103\n",
      "Epoch 49/100\n",
      "24/24 - 0s - 12ms/step - accuracy: 0.8690 - loss: 0.7606\n",
      "Epoch 50/100\n",
      "24/24 - 0s - 10ms/step - accuracy: 0.8783 - loss: 0.7015\n",
      "Epoch 51/100\n",
      "24/24 - 0s - 13ms/step - accuracy: 0.9037 - loss: 0.6416\n",
      "Epoch 52/100\n",
      "24/24 - 0s - 12ms/step - accuracy: 0.9144 - loss: 0.5884\n",
      "Epoch 53/100\n",
      "24/24 - 0s - 12ms/step - accuracy: 0.9225 - loss: 0.5535\n",
      "Epoch 54/100\n",
      "24/24 - 0s - 8ms/step - accuracy: 0.9211 - loss: 0.5255\n",
      "Epoch 55/100\n",
      "24/24 - 0s - 7ms/step - accuracy: 0.9332 - loss: 0.4952\n",
      "Epoch 56/100\n",
      "24/24 - 0s - 8ms/step - accuracy: 0.9465 - loss: 0.4567\n",
      "Epoch 57/100\n",
      "24/24 - 0s - 7ms/step - accuracy: 0.9519 - loss: 0.4168\n",
      "Epoch 58/100\n",
      "24/24 - 0s - 7ms/step - accuracy: 0.9492 - loss: 0.3882\n",
      "Epoch 59/100\n",
      "24/24 - 0s - 7ms/step - accuracy: 0.9572 - loss: 0.3646\n",
      "Epoch 60/100\n",
      "24/24 - 0s - 7ms/step - accuracy: 0.9559 - loss: 0.3580\n",
      "Epoch 61/100\n",
      "24/24 - 0s - 8ms/step - accuracy: 0.9652 - loss: 0.3361\n",
      "Epoch 62/100\n",
      "24/24 - 0s - 7ms/step - accuracy: 0.9719 - loss: 0.3086\n",
      "Epoch 63/100\n",
      "24/24 - 0s - 10ms/step - accuracy: 0.9773 - loss: 0.2785\n",
      "Epoch 64/100\n",
      "24/24 - 0s - 9ms/step - accuracy: 0.9746 - loss: 0.2579\n",
      "Epoch 65/100\n",
      "24/24 - 0s - 9ms/step - accuracy: 0.9826 - loss: 0.2364\n",
      "Epoch 66/100\n",
      "24/24 - 0s - 9ms/step - accuracy: 0.9786 - loss: 0.2227\n",
      "Epoch 67/100\n",
      "24/24 - 0s - 9ms/step - accuracy: 0.9880 - loss: 0.2089\n",
      "Epoch 68/100\n",
      "24/24 - 0s - 8ms/step - accuracy: 0.9866 - loss: 0.1966\n",
      "Epoch 69/100\n",
      "24/24 - 0s - 9ms/step - accuracy: 0.9906 - loss: 0.1853\n",
      "Epoch 70/100\n",
      "24/24 - 0s - 8ms/step - accuracy: 0.9906 - loss: 0.1714\n",
      "Epoch 71/100\n",
      "24/24 - 0s - 8ms/step - accuracy: 0.9906 - loss: 0.1614\n",
      "Epoch 72/100\n",
      "24/24 - 0s - 7ms/step - accuracy: 0.9933 - loss: 0.1531\n",
      "Epoch 73/100\n",
      "24/24 - 0s - 8ms/step - accuracy: 0.9947 - loss: 0.1433\n",
      "Epoch 74/100\n",
      "24/24 - 0s - 8ms/step - accuracy: 0.9906 - loss: 0.1343\n",
      "Epoch 75/100\n",
      "24/24 - 0s - 9ms/step - accuracy: 0.9947 - loss: 0.1292\n",
      "Epoch 76/100\n",
      "24/24 - 0s - 10ms/step - accuracy: 0.9920 - loss: 0.1232\n",
      "Epoch 77/100\n",
      "24/24 - 0s - 11ms/step - accuracy: 0.9920 - loss: 0.1180\n",
      "Epoch 78/100\n",
      "24/24 - 0s - 10ms/step - accuracy: 0.9933 - loss: 0.1181\n",
      "Epoch 79/100\n",
      "24/24 - 0s - 9ms/step - accuracy: 0.9947 - loss: 0.1049\n",
      "Epoch 80/100\n",
      "24/24 - 0s - 7ms/step - accuracy: 0.9933 - loss: 0.1005\n",
      "Epoch 81/100\n",
      "24/24 - 0s - 13ms/step - accuracy: 0.9947 - loss: 0.0918\n",
      "Epoch 82/100\n",
      "24/24 - 0s - 11ms/step - accuracy: 0.9973 - loss: 0.0865\n",
      "Epoch 83/100\n",
      "24/24 - 0s - 9ms/step - accuracy: 0.9973 - loss: 0.0829\n",
      "Epoch 84/100\n",
      "24/24 - 0s - 10ms/step - accuracy: 0.9973 - loss: 0.0808\n",
      "Epoch 85/100\n",
      "24/24 - 0s - 12ms/step - accuracy: 0.9960 - loss: 0.0743\n",
      "Epoch 86/100\n",
      "24/24 - 0s - 11ms/step - accuracy: 0.9973 - loss: 0.0726\n",
      "Epoch 87/100\n",
      "24/24 - 0s - 8ms/step - accuracy: 0.9973 - loss: 0.0685\n",
      "Epoch 88/100\n",
      "24/24 - 0s - 7ms/step - accuracy: 0.9960 - loss: 0.0672\n",
      "Epoch 89/100\n",
      "24/24 - 0s - 7ms/step - accuracy: 0.9960 - loss: 0.0637\n",
      "Epoch 90/100\n",
      "24/24 - 0s - 7ms/step - accuracy: 0.9960 - loss: 0.0663\n",
      "Epoch 91/100\n",
      "24/24 - 0s - 7ms/step - accuracy: 0.9960 - loss: 0.0638\n",
      "Epoch 92/100\n",
      "24/24 - 0s - 7ms/step - accuracy: 0.9973 - loss: 0.0649\n",
      "Epoch 93/100\n",
      "24/24 - 0s - 7ms/step - accuracy: 0.9973 - loss: 0.0573\n",
      "Epoch 94/100\n",
      "24/24 - 0s - 8ms/step - accuracy: 0.9960 - loss: 0.0532\n",
      "Epoch 95/100\n",
      "24/24 - 0s - 8ms/step - accuracy: 0.9960 - loss: 0.0512\n",
      "Epoch 96/100\n",
      "24/24 - 0s - 8ms/step - accuracy: 0.9960 - loss: 0.0470\n",
      "Epoch 97/100\n",
      "24/24 - 0s - 7ms/step - accuracy: 0.9960 - loss: 0.0458\n",
      "Epoch 98/100\n",
      "24/24 - 0s - 7ms/step - accuracy: 0.9960 - loss: 0.0454\n",
      "Epoch 99/100\n",
      "24/24 - 0s - 8ms/step - accuracy: 0.9973 - loss: 0.0442\n",
      "Epoch 100/100\n",
      "24/24 - 0s - 7ms/step - accuracy: 0.9973 - loss: 0.0412\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1f2b792b680>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X, y, epochs=100, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "17709624-f642-4d7e-84e7-d0175a09d788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.96"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sequences)/50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a39ad121-86d5-47e1-9ff4-25ae3197bb58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'villagers', 'noticed', 'him', 'immediately', 'for', 'in']\n",
      "[[1, 13, 205, 14, 206, 21, 6]]\n",
      "[[  1  13 205  14 206  21   6]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "2\n",
      "Predicted next word: 'a'\n"
     ]
    }
   ],
   "source": [
    "def predict_next_word(model, tokenizer, text, sequence_length):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    words = text.split()\n",
    "    print(words)\n",
    "    sequence = tokenizer.texts_to_sequences([words])\n",
    "    print(sequence)\n",
    "    sequence = np.array(sequence[-sequence_length+1:])\n",
    "    print(sequence)\n",
    "    predicted = model.predict(sequence)\n",
    "    predicted_word_index = np.argmax(predicted, axis=1)[0]\n",
    "    print(predicted_word_index)\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == predicted_word_index:\n",
    "            return word\n",
    "\n",
    "text = \"The villagers noticed him immediately for in\"\n",
    "predicted_word = predict_next_word(model, tokenizer, text, sequence_length)\n",
    "print(f\"Predicted next word: '{predicted_word}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90282ed0-2fcc-44a1-9c1a-8b393794b530",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99987f21-c107-4858-8c72-7d446ea78cf7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
